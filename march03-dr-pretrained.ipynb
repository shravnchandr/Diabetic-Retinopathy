{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy\nimport os\nimport pandas\nimport cv2\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Input,, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.vgg16 import VGG16","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 256\nsigmaX = 30\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[numpy.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][numpy.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][numpy.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][numpy.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][numpy.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = numpy.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aptos_df = pandas.read_csv(\"../input/aptos2019-blindness-detection/train.csv\")\ndr_df = pandas.read_csv(\"../input/diabetic-retinopathy-resized/trainLabels.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aptos_dir = \"../input/aptos2019-blindness-detection/train_images/\"\ndr_dir = \"../input/diabetic-retinopathy-resized/resized_train/resized_train/\"\n\nimages = []\nlabels = []\ncount0 = 0\n\n# for idx in tqdm(range(len(dr_df))):\n#     if dr_df.iloc[idx]['level'] == 0:\n#         if count0 < 6038:\n#             images.append(load_ben_color(dr_dir+dr_df.iloc[idx]['image']+'.jpeg'))\n#             labels.append(dr_df.iloc[idx]['level'])\n#             count0 += 1\n#     else:\n#         images.append(load_ben_color(dr_dir+dr_df.iloc[idx]['image']+'.jpeg'))\n#         labels.append(dr_df.iloc[idx]['level'])\n\nfor idx in tqdm(range(len(aptos_df))):\n    images.append(load_ben_color(aptos_dir+aptos_df.iloc[idx]['id_code']+'.png'))\n    labels.append(aptos_df.iloc[idx]['diagnosis'])\n    ","execution_count":null,"outputs":[{"output_type":"stream","text":" 64%|██████▎   | 2327/3662 [07:50<03:25,  6.48it/s]","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = numpy.array(images)\nlabels = numpy.array(labels)\ncat_labels = to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG16(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nx = GlobalAveragePooling2D()(model.output)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\nx = Dense(32, activation='relu')(x)\nop = Dense(5, activation='softmax')(x)\n\nmodel = Model(inputs=model.inputs, outputs=op)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\nmodel.fit(images, cat_labels, batch_size=32, epochs=8, shuffle=True, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResNet50(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nx = GlobalAveragePooling2D()(model.output)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\nx = Dense(32, activation='relu')(x)\nop = Dense(5, activation='softmax')(x)\n\nmodel = Model(inputs=model.inputs, outputs=op)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\nmodel.fit(images, cat_labels, batch_size=32, epochs=8, shuffle=True, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Xception(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nx = GlobalAveragePooling2D()(model.output)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\nx = Dense(32, activation='relu')(x)\nop = Dense(5, activation='softmax')(x)\n\nmodel = Model(inputs=model.inputs, outputs=op)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\nmodel.fit(images, cat_labels, batch_size=32, epochs=8, shuffle=True, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}