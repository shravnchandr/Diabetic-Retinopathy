{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy\nimport numpy as np\nimport os\nimport pandas\nimport cv2\nfrom tqdm import tqdm\nimport random\n\nimport tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout, Lambda, AveragePooling2D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 256\nsigmaX = 30\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[numpy.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][numpy.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][numpy.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][numpy.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][numpy.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = numpy.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aptos_df = pandas.read_csv(\"../input/aptos2019-blindness-detection/train.csv\")\ndr_df = pandas.read_csv(\"../input/diabetic-retinopathy-resized/trainLabels.csv\")","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aptos_dir = \"../input/aptos2019-blindness-detection/train_images/\"\ndr_dir = \"../input/diabetic-retinopathy-resized/resized_train/resized_train/\"\n\nimages = []\nlabels = []\ncount0 = 0\n\n# for idx in tqdm(range(len(dr_df))):\n#     if dr_df.iloc[idx]['level'] == 0:\n#         if count0 < 6038:\n#             images.append(load_ben_color(dr_dir+dr_df.iloc[idx]['image']+'.jpeg'))\n#             labels.append(dr_df.iloc[idx]['level'])\n#             count0 += 1\n#     else:\n#         images.append(load_ben_color(dr_dir+dr_df.iloc[idx]['image']+'.jpeg'))\n#         labels.append(dr_df.iloc[idx]['level'])\n\nfor idx in tqdm(range(len(aptos_df))):\n    images.append(load_ben_color(aptos_dir+aptos_df.iloc[idx]['id_code']+'.png'))\n    labels.append(aptos_df.iloc[idx]['diagnosis'])","execution_count":5,"outputs":[{"output_type":"stream","text":"100%|██████████| 3662/3662 [13:28<00:00,  4.53it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = numpy.array(images)\nlabels = numpy.array(labels)\ncat_labels = to_categorical(labels)\n\nimages = images.astype('float32') / 255.0\nlabels = labels.astype('float32')\nimages = images.reshape(images.shape[0], IMG_SIZE, IMG_SIZE,3)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (IMG_SIZE, IMG_SIZE, 3)\nnum_classes = 5","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def euclid_distance(vects):\n    x,y = vects\n    sum_square = K.sum(K.square(x-y), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n \ndef euclid_distance_output_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def contrastive_loss(y_true, y_pred):\n    y_true=tf.dtypes.cast(y_true, tf.float64)\n    y_pred=tf.dtypes.cast(y_pred, tf.float64)\n    margin = 1\n    square_pred = K.square(y_pred)\n    margin_square = K.square(K.maximum(margin - y_pred, 0))\n    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_pairs(x, digit_indices):\n    pairs = []\n    labels = []\n\n    n=min([len(digit_indices[d]) for d in range(num_classes)]) -1\n\n    for d in range(num_classes):\n        for i in range(n):\n            z1, z2 = digit_indices[d][i], digit_indices[d][i+1]\n            pairs += [[x[z1], x[z2]]]\n            inc = random.randrange(1, num_classes)\n            dn = (d + inc) % num_classes\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n            pairs += [[x[z1], x[z2]]]\n            labels += [1,0]\n    return np.array(pairs), np.array(labels)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_accuracy(y_true, y_pred):\n    pred = y_pred.ravel() < 0.5\n    return np.mean(pred == y_true)\n \ndef accuracy(y_true, y_pred):\n    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_base_net(input_shape):\n    input_ = Input(shape = input_shape)\n    x = Conv2D(4, (5,5), activation = 'relu')(input_)\n    x = AveragePooling2D(pool_size = (2,2))(x)\n    x = Conv2D(4, (5,5), activation = 'relu')(input_)\n    x = MaxPooling2D(pool_size = (2,2))(x)\n    \n    x = Conv2D(4, (5,5), activation = 'relu')(input_)\n    x = AveragePooling2D(pool_size = (2,2))(x)\n    x = Conv2D(16, (5,5), activation = 'relu')(x)\n    x = AveragePooling2D(pool_size = (2,2))(x)\n    \n    x = Flatten()(x)\n    x = Dense(1024, activation = 'tanh')(x)\n    model = Model(input_, x)\n    #   model.summary()\n\n    return model","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"digit_indices = [np.where(labels == i)[0] for i in range(num_classes)]\ntr_pairs, tr_y = create_pairs(images, digit_indices) \nbase_network = create_base_net(input_shape)","execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'inputs_' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-b18f893aa348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdigit_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtr_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbase_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_base_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-18cb7989a0a1>\u001b[0m in \u001b[0;36mcreate_base_net\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#   model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'inputs_' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_a = Input(shape=input_shape)\ninput_b = Input(shape=input_shape)\n \nprocessed_a = base_network(input_a)\nprocessed_b = base_network(input_b)\n \ndistance = Lambda(euclid_distance, output_shape=euclid_distance_output_shape)([processed_a, processed_b])\n \nmodel = Model([input_a, input_b], distance)\n#train\nmodel.compile(loss=contrastive_loss, optimizer='adam', metrics=[accuracy])\nmodel.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y, batch_size=128, epochs= 16, validation_split=0.1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}