{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy\nimport cv2\nfrom tensorflow.keras.utils import to_categorical\nfrom tqdm import tqdm\nimport pandas","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 256\nsigmaX = 30\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[numpy.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][numpy.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][numpy.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][numpy.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][numpy.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = numpy.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n    return image","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aptos_df = pandas.read_csv(\"../input/aptos2019-blindness-detection/train.csv\")\ndr_df = pandas.read_csv(\"../input/diabetic-retinopathy-resized/trainLabels.csv\")\nprint(aptos_df['diagnosis'].value_counts())\nprint(dr_df['level'].value_counts())","execution_count":3,"outputs":[{"output_type":"stream","text":"0    1805\n2     999\n1     370\n4     295\n3     193\nName: diagnosis, dtype: int64\n0    25810\n2     5292\n1     2443\n3      873\n4      708\nName: level, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\nimport pandas\n\naptos_df = pandas.read_csv(\"../input/aptos2019-blindness-detection/train.csv\")\naptos_dir = \"../input/aptos2019-blindness-detection/train_images/\"\nimages = []\nlabels = []\n\nfor idx in tqdm(range(len(aptos_df))):\n    images.append(load_ben_color(aptos_dir+aptos_df.iloc[idx]['id_code']+'.png', 20))\n    labels.append(aptos_df.iloc[idx]['diagnosis'])\n\nfrom tensorflow.keras.utils import to_categorical\n# images = numpy.load('../input/aptosnumpy/images.npy')\nimages = numpy.array(images)\nlabels = numpy.array(labels)\ncat_labels = to_categorical(labels)\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(images, cat_labels, \n                                                    test_size=0.1, shuffle=True,\n                                                    random_state=42, stratify=labels)","execution_count":null,"outputs":[{"output_type":"stream","text":"  1%|‚ñè         | 52/3662 [00:13<20:58,  2.87it/s]","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=90,\n    shear_range=0.25,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     zca_whitening=True,\n    zoom_range=[0.75,1.25],\n    vertical_flip=True,\n    horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\ntest_datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=90,\n    shear_range=0.25,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     zca_whitening=True,\n    zoom_range=[0.75,1.25],\n    vertical_flip=True,\n    horizontal_flip=True)\ntest_datagen.fit(x_test)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced', numpy.unique(labels), labels)\nd_class_weights = dict(enumerate(class_weights))\nd_class_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB4\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n\nmodel = Xception(include_top=False)#, drop_connect_rate=0.4)#, input_shape=(256, 256, 3))\nx = GlobalMaxPooling2D()(model.output)\nx = Dropout(0.4)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.4)(x)\nx = Dense(256, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\nop = Dense(5, activation='softmax')(x)\n\nmodel = Model(inputs=model.inputs, outputs=op)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n\ncheckpoint = tensorflow.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', \n                                                        save_best_only=True, verbose=1)\nearlystopping = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, \n                                                         restore_best_weights=True, verbose=1)\nreduceLR = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1,\n                                                        patience=4, verbose=1)\n\n\nmodel.fit(train_datagen.flow(x_train, y_train, batch_size=32),\n          steps_per_epoch=len(x_train) / 32, epochs=128, verbose=1,\n          validation_data = (train_datagen.flow(x_train, y_train, batch_size=32)),\n          callbacks=[checkpoint, earlystopping, reduceLR])#, class_weight=d_class_weights)","execution_count":5,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 1s 0us/step\nEpoch 1/128\n102/102 [==============================] - 119s 1s/step - loss: 1.1778 - accuracy: 0.5623 - val_loss: 8.5444 - val_accuracy: 0.3678\n\nEpoch 00001: val_accuracy improved from -inf to 0.36783, saving model to model.h5\nEpoch 2/128\n102/102 [==============================] - 109s 1s/step - loss: 0.7357 - accuracy: 0.7297 - val_loss: 2.7139 - val_accuracy: 0.5284\n\nEpoch 00002: val_accuracy improved from 0.36783 to 0.52838, saving model to model.h5\nEpoch 3/128\n102/102 [==============================] - 107s 1s/step - loss: 0.6262 - accuracy: 0.7562 - val_loss: 0.6236 - val_accuracy: 0.7678\n\nEpoch 00003: val_accuracy improved from 0.52838 to 0.76783, saving model to model.h5\nEpoch 4/128\n102/102 [==============================] - 107s 1s/step - loss: 0.5828 - accuracy: 0.7630 - val_loss: 0.6360 - val_accuracy: 0.7560\n\nEpoch 00004: val_accuracy did not improve from 0.76783\nEpoch 5/128\n102/102 [==============================] - 107s 1s/step - loss: 0.5591 - accuracy: 0.7715 - val_loss: 0.5485 - val_accuracy: 0.7866\n\nEpoch 00005: val_accuracy improved from 0.76783 to 0.78665, saving model to model.h5\nEpoch 6/128\n102/102 [==============================] - 107s 1s/step - loss: 0.5332 - accuracy: 0.7918 - val_loss: 2.4159 - val_accuracy: 0.4920\n\nEpoch 00006: val_accuracy did not improve from 0.78665\nEpoch 7/128\n102/102 [==============================] - 107s 1s/step - loss: 0.5444 - accuracy: 0.8035 - val_loss: 0.4986 - val_accuracy: 0.8188\n\nEpoch 00007: val_accuracy improved from 0.78665 to 0.81882, saving model to model.h5\nEpoch 8/128\n102/102 [==============================] - 106s 1s/step - loss: 0.5148 - accuracy: 0.8125 - val_loss: 0.6333 - val_accuracy: 0.7624\n\nEpoch 00008: val_accuracy did not improve from 0.81882\nEpoch 9/128\n102/102 [==============================] - 106s 1s/step - loss: 0.5342 - accuracy: 0.7945 - val_loss: 0.5466 - val_accuracy: 0.7888\n\nEpoch 00009: val_accuracy did not improve from 0.81882\nEpoch 10/128\n102/102 [==============================] - 107s 1s/step - loss: 0.5048 - accuracy: 0.8040 - val_loss: 0.8038 - val_accuracy: 0.7144\n\nEpoch 00010: val_accuracy did not improve from 0.81882\nEpoch 11/128\n102/102 [==============================] - 106s 1s/step - loss: 0.5165 - accuracy: 0.7973 - val_loss: 0.5686 - val_accuracy: 0.7979\n\nEpoch 00011: val_accuracy did not improve from 0.81882\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\nEpoch 12/128\n102/102 [==============================] - 106s 1s/step - loss: 0.4381 - accuracy: 0.8284 - val_loss: 0.4101 - val_accuracy: 0.8410\n\nEpoch 00012: val_accuracy improved from 0.81882 to 0.84097, saving model to model.h5\nEpoch 13/128\n102/102 [==============================] - 107s 1s/step - loss: 0.4060 - accuracy: 0.8432 - val_loss: 0.3886 - val_accuracy: 0.8440\n\nEpoch 00013: val_accuracy improved from 0.84097 to 0.84401, saving model to model.h5\nEpoch 14/128\n102/102 [==============================] - 106s 1s/step - loss: 0.4250 - accuracy: 0.8348 - val_loss: 0.3977 - val_accuracy: 0.8428\n\nEpoch 00014: val_accuracy did not improve from 0.84401\nEpoch 15/128\n102/102 [==============================] - 106s 1s/step - loss: 0.4033 - accuracy: 0.8456 - val_loss: 0.3686 - val_accuracy: 0.8546\n\nEpoch 00015: val_accuracy improved from 0.84401 to 0.85463, saving model to model.h5\nEpoch 16/128\n102/102 [==============================] - 108s 1s/step - loss: 0.3938 - accuracy: 0.8457 - val_loss: 0.3678 - val_accuracy: 0.8546\n\nEpoch 00016: val_accuracy did not improve from 0.85463\nEpoch 17/128\n102/102 [==============================] - 106s 1s/step - loss: 0.4107 - accuracy: 0.8320 - val_loss: 0.3641 - val_accuracy: 0.8595\n\nEpoch 00017: val_accuracy improved from 0.85463 to 0.85948, saving model to model.h5\nEpoch 18/128\n102/102 [==============================] - 106s 1s/step - loss: 0.3966 - accuracy: 0.8406 - val_loss: 0.3733 - val_accuracy: 0.8519\n\nEpoch 00018: val_accuracy did not improve from 0.85948\nEpoch 19/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3819 - accuracy: 0.8504 - val_loss: 0.3481 - val_accuracy: 0.8649\n\nEpoch 00019: val_accuracy improved from 0.85948 to 0.86495, saving model to model.h5\nEpoch 20/128\n102/102 [==============================] - 106s 1s/step - loss: 0.3887 - accuracy: 0.8500 - val_loss: 0.3439 - val_accuracy: 0.8665\n\nEpoch 00020: val_accuracy improved from 0.86495 to 0.86646, saving model to model.h5\nEpoch 21/128\n102/102 [==============================] - 108s 1s/step - loss: 0.3748 - accuracy: 0.8540 - val_loss: 0.3424 - val_accuracy: 0.8653\n\nEpoch 00021: val_accuracy did not improve from 0.86646\nEpoch 22/128\n102/102 [==============================] - 108s 1s/step - loss: 0.3502 - accuracy: 0.8663 - val_loss: 0.3352 - val_accuracy: 0.8707\n\nEpoch 00022: val_accuracy improved from 0.86646 to 0.87071, saving model to model.h5\nEpoch 23/128\n102/102 [==============================] - 108s 1s/step - loss: 0.3755 - accuracy: 0.8585 - val_loss: 0.3505 - val_accuracy: 0.8619\n\nEpoch 00023: val_accuracy did not improve from 0.87071\nEpoch 24/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3548 - accuracy: 0.8690 - val_loss: 0.3147 - val_accuracy: 0.8762\n\nEpoch 00024: val_accuracy improved from 0.87071 to 0.87618, saving model to model.h5\nEpoch 25/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3567 - accuracy: 0.8644 - val_loss: 0.3197 - val_accuracy: 0.8753\n\nEpoch 00025: val_accuracy did not improve from 0.87618\nEpoch 26/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3409 - accuracy: 0.8704 - val_loss: 0.3148 - val_accuracy: 0.8844\n\nEpoch 00026: val_accuracy improved from 0.87618 to 0.88437, saving model to model.h5\nEpoch 27/128\n102/102 [==============================] - 106s 1s/step - loss: 0.3679 - accuracy: 0.8558 - val_loss: 0.3126 - val_accuracy: 0.8765\n\nEpoch 00027: val_accuracy did not improve from 0.88437\nEpoch 28/128\n102/102 [==============================] - 106s 1s/step - loss: 0.3376 - accuracy: 0.8719 - val_loss: 0.3015 - val_accuracy: 0.8838\n\nEpoch 00028: val_accuracy did not improve from 0.88437\nEpoch 29/128\n102/102 [==============================] - 106s 1s/step - loss: 0.3447 - accuracy: 0.8690 - val_loss: 0.3152 - val_accuracy: 0.8835\n\nEpoch 00029: val_accuracy did not improve from 0.88437\nEpoch 30/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3188 - accuracy: 0.8784 - val_loss: 0.2817 - val_accuracy: 0.8944\n\nEpoch 00030: val_accuracy improved from 0.88437 to 0.89439, saving model to model.h5\nEpoch 31/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3020 - accuracy: 0.8870 - val_loss: 0.2931 - val_accuracy: 0.8868\n\nEpoch 00031: val_accuracy did not improve from 0.89439\nEpoch 32/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3176 - accuracy: 0.8786 - val_loss: 0.2792 - val_accuracy: 0.8932\n\nEpoch 00032: val_accuracy did not improve from 0.89439\nEpoch 33/128\n102/102 [==============================] - 108s 1s/step - loss: 0.3047 - accuracy: 0.8795 - val_loss: 0.2920 - val_accuracy: 0.8877\n\nEpoch 00033: val_accuracy did not improve from 0.89439\nEpoch 34/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3107 - accuracy: 0.8806 - val_loss: 0.3005 - val_accuracy: 0.8838\n\nEpoch 00034: val_accuracy did not improve from 0.89439\n\nEpoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\nEpoch 35/128\n102/102 [==============================] - 107s 1s/step - loss: 0.3109 - accuracy: 0.8807 - val_loss: 0.2597 - val_accuracy: 0.8983\n\nEpoch 00035: val_accuracy improved from 0.89439 to 0.89833, saving model to model.h5\nEpoch 36/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2819 - accuracy: 0.8898 - val_loss: 0.2493 - val_accuracy: 0.9011\n\nEpoch 00036: val_accuracy improved from 0.89833 to 0.90106, saving model to model.h5\nEpoch 37/128\n","name":"stdout"},{"output_type":"stream","text":"102/102 [==============================] - 107s 1s/step - loss: 0.2911 - accuracy: 0.8711 - val_loss: 0.2392 - val_accuracy: 0.9105\n\nEpoch 00037: val_accuracy improved from 0.90106 to 0.91047, saving model to model.h5\nEpoch 38/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2913 - accuracy: 0.8903 - val_loss: 0.2455 - val_accuracy: 0.9071\n\nEpoch 00038: val_accuracy did not improve from 0.91047\nEpoch 39/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2792 - accuracy: 0.8939 - val_loss: 0.2332 - val_accuracy: 0.9135\n\nEpoch 00039: val_accuracy improved from 0.91047 to 0.91351, saving model to model.h5\nEpoch 40/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2668 - accuracy: 0.8971 - val_loss: 0.2389 - val_accuracy: 0.9093\n\nEpoch 00040: val_accuracy did not improve from 0.91351\nEpoch 41/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2577 - accuracy: 0.8992 - val_loss: 0.2325 - val_accuracy: 0.9165\n\nEpoch 00041: val_accuracy improved from 0.91351 to 0.91654, saving model to model.h5\nEpoch 42/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2788 - accuracy: 0.9011 - val_loss: 0.2345 - val_accuracy: 0.9156\n\nEpoch 00042: val_accuracy did not improve from 0.91654\nEpoch 43/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2677 - accuracy: 0.8959 - val_loss: 0.2247 - val_accuracy: 0.9153\n\nEpoch 00043: val_accuracy did not improve from 0.91654\nEpoch 44/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2582 - accuracy: 0.9000 - val_loss: 0.2361 - val_accuracy: 0.9114\n\nEpoch 00044: val_accuracy did not improve from 0.91654\nEpoch 45/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2487 - accuracy: 0.9022 - val_loss: 0.2344 - val_accuracy: 0.9074\n\nEpoch 00045: val_accuracy did not improve from 0.91654\n\nEpoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\nEpoch 46/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2631 - accuracy: 0.9033 - val_loss: 0.2249 - val_accuracy: 0.9138\n\nEpoch 00046: val_accuracy did not improve from 0.91654\nEpoch 47/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2433 - accuracy: 0.9121 - val_loss: 0.2241 - val_accuracy: 0.9178\n\nEpoch 00047: val_accuracy improved from 0.91654 to 0.91775, saving model to model.h5\nEpoch 48/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2328 - accuracy: 0.9138 - val_loss: 0.2274 - val_accuracy: 0.9168\n\nEpoch 00048: val_accuracy did not improve from 0.91775\nEpoch 49/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2441 - accuracy: 0.9035 - val_loss: 0.2311 - val_accuracy: 0.9141\n\nEpoch 00049: val_accuracy did not improve from 0.91775\nEpoch 50/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2631 - accuracy: 0.8996 - val_loss: 0.2231 - val_accuracy: 0.9150\n\nEpoch 00050: val_accuracy did not improve from 0.91775\nEpoch 51/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2490 - accuracy: 0.9124 - val_loss: 0.2260 - val_accuracy: 0.9074\n\nEpoch 00051: val_accuracy did not improve from 0.91775\n\nEpoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\nEpoch 52/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2567 - accuracy: 0.8981 - val_loss: 0.2227 - val_accuracy: 0.9181\n\nEpoch 00052: val_accuracy improved from 0.91775 to 0.91806, saving model to model.h5\nEpoch 53/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2651 - accuracy: 0.8965 - val_loss: 0.2277 - val_accuracy: 0.9202\n\nEpoch 00053: val_accuracy improved from 0.91806 to 0.92018, saving model to model.h5\nEpoch 54/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2476 - accuracy: 0.9077 - val_loss: 0.2265 - val_accuracy: 0.9141\n\nEpoch 00054: val_accuracy did not improve from 0.92018\nEpoch 55/128\n102/102 [==============================] - 106s 1s/step - loss: 0.2659 - accuracy: 0.9091 - val_loss: 0.2247 - val_accuracy: 0.9165\n\nEpoch 00055: val_accuracy did not improve from 0.92018\nEpoch 56/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2555 - accuracy: 0.9001 - val_loss: 0.2232 - val_accuracy: 0.9205\n\nEpoch 00056: val_accuracy improved from 0.92018 to 0.92049, saving model to model.h5\nEpoch 57/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2616 - accuracy: 0.8991 - val_loss: 0.2303 - val_accuracy: 0.9165\n\nEpoch 00057: val_accuracy did not improve from 0.92049\nEpoch 58/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2531 - accuracy: 0.9005 - val_loss: 0.2224 - val_accuracy: 0.9165\n\nEpoch 00058: val_accuracy did not improve from 0.92049\nEpoch 59/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2465 - accuracy: 0.9111 - val_loss: 0.2211 - val_accuracy: 0.9205\n\nEpoch 00059: val_accuracy did not improve from 0.92049\nEpoch 60/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2496 - accuracy: 0.9022 - val_loss: 0.2263 - val_accuracy: 0.9150\n\nEpoch 00060: val_accuracy did not improve from 0.92049\n\nEpoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\nEpoch 61/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2588 - accuracy: 0.9025 - val_loss: 0.2255 - val_accuracy: 0.9156\n\nEpoch 00061: val_accuracy did not improve from 0.92049\nEpoch 62/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2889 - accuracy: 0.8917 - val_loss: 0.2328 - val_accuracy: 0.9111\n\nEpoch 00062: val_accuracy did not improve from 0.92049\nEpoch 63/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2577 - accuracy: 0.8980 - val_loss: 0.2268 - val_accuracy: 0.9123\n\nEpoch 00063: val_accuracy did not improve from 0.92049\nEpoch 64/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2465 - accuracy: 0.9019 - val_loss: 0.2219 - val_accuracy: 0.9223\n\nEpoch 00064: val_accuracy improved from 0.92049 to 0.92231, saving model to model.h5\nEpoch 65/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2550 - accuracy: 0.8970 - val_loss: 0.2303 - val_accuracy: 0.9123\n\nEpoch 00065: val_accuracy did not improve from 0.92231\nEpoch 66/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2827 - accuracy: 0.8931 - val_loss: 0.2264 - val_accuracy: 0.9141\n\nEpoch 00066: val_accuracy did not improve from 0.92231\nEpoch 67/128\n102/102 [==============================] - 106s 1s/step - loss: 0.2689 - accuracy: 0.9026 - val_loss: 0.2300 - val_accuracy: 0.9153\n\nEpoch 00067: val_accuracy did not improve from 0.92231\nEpoch 68/128\n102/102 [==============================] - 106s 1s/step - loss: 0.2531 - accuracy: 0.9049 - val_loss: 0.2234 - val_accuracy: 0.9208\n\nEpoch 00068: val_accuracy did not improve from 0.92231\n\nEpoch 00068: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\nEpoch 69/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2341 - accuracy: 0.9114 - val_loss: 0.2178 - val_accuracy: 0.9181\n\nEpoch 00069: val_accuracy did not improve from 0.92231\nEpoch 70/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2642 - accuracy: 0.8993 - val_loss: 0.2341 - val_accuracy: 0.9117\n\nEpoch 00070: val_accuracy did not improve from 0.92231\nEpoch 71/128\n102/102 [==============================] - 107s 1s/step - loss: 0.2577 - accuracy: 0.9082 - val_loss: 0.2292 - val_accuracy: 0.9193\n\nEpoch 00071: val_accuracy did not improve from 0.92231\nEpoch 72/128\n102/102 [==============================] - 108s 1s/step - loss: 0.2503 - accuracy: 0.9107 - val_loss: 0.2320 - val_accuracy: 0.9165\n\nEpoch 00072: val_accuracy did not improve from 0.92231\nRestoring model weights from the end of the best epoch.\n\nEpoch 00072: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\nEpoch 00072: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f505c378bd0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}